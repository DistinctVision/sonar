## Однородные координаты.  

В предыдущей статье мы рассматривали эвклидово пространство. 
Точки в двумерном эвклидовом пространстве обозначаются при помощи двумерных векторов $\begin{pmatrix} x & y \end{pmatrix}^T$. А такое пространство обозначается как $\mathbb{R}^2$. $\begin{pmatrix} x & y \end{pmatrix}^T \in \mathbb{R}^2$.  
Введем понятие проективного пространства. Оно обозначается как $\mathbb{P}^2$ (projective
space). Чтобы перевести вектор из двумерного эвклидового пространства и перевести его в проективное, нужно взять любой ненулевой скаляр, умножить на него вектор и добавить этот скаляр в качестве последней компоненты: $\vec v = \begin{pmatrix} x & y \end{pmatrix}^T \in \mathbb{R}^2 \space \rightarrow \space \vec p = \begin{pmatrix} x \cdot w & y \cdot w & w \end{pmatrix}^T \in \mathbb{P}^2$. Получаем координаты точки в уже в однородных координатах (homogeneous coordinates) проективного пространства. Таким образом одной точке проективного пространства принадлежит бесконечное множество точек эвклидового пространства. Чтобы перевести однородные координаты точки обратно в эвклидово простраство, нужно соответственно разделить вектор на его последнюю компоненту и удалить ее же из вектора: $\vec p = \begin{pmatrix} x & y & w \end{pmatrix}^T \in \mathbb{P}^2 \space \rightarrow \space \vec v = \begin{pmatrix} \frac{x}{w} & \frac{y}{w} \end{pmatrix}^T \in \mathbb{R}^2$.  
Тут же можно заметить, что умножение однородных координат на скаляр не меняет координат соответствующих точек в эвклидовом пространстве: $\vec{p_B} = \vec{p_A} \cdot s = \begin{pmatrix} x \cdot s & y \cdot s & w \cdot s \end{pmatrix}^T \in \mathbb{P}^2 \space \rightarrow \space \vec v = \begin{pmatrix} \frac{x \cdot s}{w \cdot s} & \frac{y \cdot s}{w \cdot s} \end{pmatrix}^T = \begin{pmatrix} \frac{x}{w} & \frac{y}{w} \end{pmatrix}^T \in \mathbb{R}^2$.  
Также, если последняя компонента равна 0, то такую точку мы не сможем перевести в эвклидово пространство: $\vec p = \begin{pmatrix} x & y & 0 \end{pmatrix}^T \in \mathbb{P}^2$ – такая точка называется точкой на бесконечности (point at infinity или ideal point).  
При переводе эвклидовых координат в однородные удобно в качестве скаляра, на который умножается вектор, брать 1: $\vec v = \begin{pmatrix} x & y \end{pmatrix}^T \in \mathbb{R}^2 \space \rightarrow \space \vec p = \begin{pmatrix} x & y & 1 \end{pmatrix}^T \in \mathbb{P}^2$.  
Перевод обратно в таком случае также упрощается: $\vec p = \begin{pmatrix} x & y & 1 \end{pmatrix}^T \in \mathbb{P}^2 \space \rightarrow \space \vec v = \begin{pmatrix} x & y \end{pmatrix}^T \in \mathbb{R}^2$.  
Из уроков школьной геометрии мы помним уравнение линии: $y = k \cdot x + b$, где коэффициенты $k$ и $b$ определяют нашу линию. Но удобнее рассматривать линии в другой форме: $a \cdot x + b \cdot y + c = 0$. Можем вывести соотношение этих коэффициентов: $a = k_{line}, \space b = -1, \space c = b_{line}$. А еще удобнее перевести набор коэффициентов в вектор-строку: $l = \begin{pmatrix} a & b & c \end{pmatrix}$.  
Разобравшись с однородными координатами, мы можем теперь рассмотреть свойства точек и линий в этих координатах:  
* Так как $a \cdot x + b \cdot y + c = 0$, то точка лежит на линии. В однородных координатах может записать это так: $l \cdot \vec v = \begin{pmatrix} a & b & c \end{pmatrix} \cdot \begin{pmatrix} x \\ y \\ 1 \end{pmatrix} = 0$.
* Первые две компоненты линии $l$ ($a$ и $b$) - это вектор-перпендикуляр к этой самой линии в эвклидовых координатах. Можно этот вектор нормализовать, тогда компонента $с$ будет равна расстоянию линии до начала координат. А умножая вектор линии на вектор точки, получим величину расстояния от линии до точки: $l = \begin{pmatrix} a & b & c \end{pmatrix}, \vec v = \begin{pmatrix} x & y & 1 \end{pmatrix}^T, \space \space distance(l, \vec v) = (\frac{l}{|\begin{pmatrix} a & b \end{pmatrix}^T|}) \cdot \begin{pmatrix} x & y & 1 \end{pmatrix}^T$. Полученное величина может быть больше или меньше нуля, в зависимости от того, с какой стороны от линии находится точка. 
* Вектор линии $l$ из двух точек $\vec{p_A}$ и $\vec{p_B}$ можно получить их векторным произведением: $l = (\vec{p_A} \times \vec{p_B})^T$.
* Координаты точки пересечения $\vec p$ двух линий $l_A$ и $l_B$ можно получить их векторным произведением: $\vec{p} = \vec{{l_A}^T} \times \vec{{l_B}^T}$. Если линии параллельны, то $p_w = 0$ - а значит получим точку на бесконечности и не сможем перевести ее в эвклидово пространство. Также вектор $\vec n = \begin{pmatrix} p_x & p_y \end{pmatrix}^T$ - будет перпендикуляром к исходным линиям.  
* Возьмем две точки на бесконечности $\vec{p_A} = \begin{pmatrix} {p_A}_x & {p_A}_y & 0 \end{pmatrix}^T$, $\vec{p_B} = \begin{pmatrix} {p_B}_x & {p_B}_y & 0 \end{pmatrix}^T$ и найдем линию, пересекающую эти две точки: $l = (\vec{p_A} \times \vec{p_B})^T$. В результате получим линию, первые две компоненты вектора которой равны нулю: $l = (\vec{p_A} \times \vec{p_B})^T = \begin{pmatrix} 0 & 0 & {p_A}_x \cdot {p_B}_y - {p_A}_y \cdot {p_B}_x \end{pmatrix}$. Такую линию мы не сможем отобразить в эвклидовом пространстве. Называется она линией на бесконечности (line at infinity). Она не имеет перпендикуляра и пересекается со всеми точками на бесконечности.  

## Трансформации в однородных координатах.  
Все описанные трансформации можно выполнять и для однородных координат.  
Для примера возьмем поворот точек матрицей поворота в эвклидовом пространстве:  $\vec{v'} = R \vec{v} = \begin{pmatrix} R_{11} & R_{12} \\ R_{21} & R_{22} \end{pmatrix} \begin{pmatrix} v_x \\ v_y \end{pmatrix} = \begin{pmatrix} {v'}_x \\ {v'}_y \end{pmatrix}$.  
В однородных координатах это принимает такую форму:  $\vec{v'} = R \vec{v} = \begin{pmatrix} R_{11} & R_{12} & 0 \\ R_{21} & R_{22} & 0 \\ 0 & 0 & 1 \end{pmatrix} \begin{pmatrix} v_x \\ v_y \\ 1 \end{pmatrix} = \begin{pmatrix} {v'}_x \\ {v'}_y \\ 1 \end{pmatrix}$  
В эвклидовых координатах перемещение выполнялось следующим образом: $\vec{v'} = \vec v + \vec t$.  
Смещение объекта - это нелинейная операция в эвклидовом пространстве. Но в проективном пространстве смещение можно реализовать при помощи матрицы $T$:  $\vec{v'} = \begin{pmatrix} 0 & 0 & t_x \\ 0 & 0 & t_y \\ 0 & 0 & 1 \end{pmatrix} \begin{pmatrix} v_x & v_y & 1 \end{pmatrix} = \begin{pmatrix} v_x + t_x \\ v_y + t_y \\ 1 \end{pmatrix}$. Таким образом смещение становится линейной операцией.  
Из предыдущей статьи мы помним, что линейные трансформации, представленные матрицами, мы можем объединять. Объединим поворот и смещение:  
$\vec{v'} = T \cdot R \cdot \vec v = \begin{pmatrix} 0 & 0 & t_x \\ 0 & 0 & t_y \\ 0 & 0 & 1 \end{pmatrix} \cdot \begin{pmatrix} R_{11} & R_{12} & 0 \\ R_{21} & R_{22} & 0 \\ 0 & 0 & 1 \end{pmatrix} \cdot \begin{pmatrix} v_x \\ v_y \\ 1 \end{pmatrix} = \begin{pmatrix} R_{11} & R_{12} & t_x \\ R_{21} & R_{22} & t_y \\ 0 & 0 & 1 \end{pmatrix} \cdot \begin{pmatrix} v_x \\ v_y \\ 1 \end{pmatrix}$  
Пусть $P = T \cdot R$, тогда $\vec{v'} = P \cdot \vec{v}$, где $P = \begin{pmatrix} R_{11} & R_{12} & t_x \\ R_{21} & R_{22} & t_y \\ 0 & 0 & 1 \end{pmatrix}$.  

## Метод наименьших квадратов
Прежде чем двигаться дальше, вооружимся новым инструментом - методом наименьших квадратов (МНК).  
Возьмем для примера такую систему линейных уравнений:  
$\begin{cases} A_{11} \cdot x_1 + A_{12} \cdot x_2 = b_1 \\ A_{21} \cdot x_1 + A_{22} \cdot x_2 = b_2 \\ A_{31} \cdot x_1 + A_{32} \cdot x_1 = b_3\end{cases}$  
Это переопределенная система уравнений, а значит решения одних уравнений может противоречить другим и система может не иметь точного решения. Ошибка получаемых решений - это обычное для вычислительной математики. Важным моментом моментом является выбор функции для вычисления ошибки. Значения $b_i$ нам известен заранее, но от системы уравнений при подставлении значений $x_i$ из-за ошибки получаем отличающиеся значения, которые мы обозначим как ${b'}_i$. Функцию ошибку как разницу суммы квадратов разницы отклонений значений $b_i$: $r(\vec x) = \sum{r_i} = \sum{({b'}_i - b_i)}$.  
Эту систему можно представить в матричном виде:  
$\begin{pmatrix} A_{11} & A_{12} \\ A_{21} & A_{22} \\ A_{31} & A_{32} \end{pmatrix} \cdot \begin{pmatrix} x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix} b_1 \\ b_2 \\ b_3 \end{pmatrix} = A \cdot \vec{x} = \vec{b}$.  
В матричном виде задачу минимизации суммы отклонений можно записать так: $(A \vec x - \vec b)^T (A \vec x - \vec b) \rightarrow min$.  
Решение нашей системы:  
$A \cdot \vec x = \vec b \space \Rightarrow \space A^T \cdot A \cdot \vec x = A^T \vec b \space \Rightarrow \space \vec x = (A^T \cdot A)^{-1} \cdot A^T \cdot \vec b$  
$\vec x = (A^T A)^{-1} A^T \vec b$  
Применение метода несколько шире, чем описанное выше. Мы определили функцию ошибки как сумму квадратов отклонений. А дальше нам нужно найти минимум этой функции. Минимум функции нужно искать в ее экстремумах. Для того, чтобы ее найти, определим систему уравнений из производных функции по каждой свободной переменной приравненных к нулю:  
$\begin{cases}\frac{\partial r(\vec x)}{\partial x_0} = 0 \\ .. \\ \frac{\partial r(\vec x)}{\partial x_n} = 0 \end{cases}$  
Получим систему уравнений, которая в отличии от предыдущей, будет не переопределена. Если система уравнений - линейная, то решение будет только одно и получить его не составляет труда. И что нам важно, оно будет удовлетворять условию, определяемую нашей функцией ошибки: $\sum{r_i} \rightarrow min$.